\section{Contribution, Benefits \& Limitations}

With this study, we contributed a new approach to automatically detect conflicts in visuo-haptic sensory integration based on analyzing event-related brain potentials. We demonstrated in eleven participants using EEG recordings that our method is able to correctly detect prematurely given visuo-haptic feedback (combinations of visual, vibration and EMS). In the future, this approach might thus be used in combination with questionnaires such as IPQ or as an alternative measure that does not require interrupting the user.

We argue in favor of the scalability of our findings to complex environments: Successfully performing intended motor actions is the most fundamental way we interact with our environment. The ERP negativity paradigm relies on the fact that during well-known tasks (e.g. motor tasks) prediction errors elicit negative signals when the environment has a useful level of predictability. In fact, ERPs have been shown to model prediction mismatches in fairly complex setups such as: robotic arm control, driving, and gaming ~\cite{Salazar-Gomez2017,Chavarriaga2015,B.2018}. Furthermore, current trends in neuroadaptive technologies emphasize the scalability of these signals beyond simple tasks~\cite{zander_neuroadaptive_2016}. These findings suggest that this effect will be consistent in other, more complex, VR tasks that also require motor commands such as touching objects.

\subsection{Implications for the future of VR Research}

We believe that this is a first step towards a potential metric for visuo-haptic immersion based on detecting visuo-haptic mismatches. If follow up studies replicate the reported patterns of ERP modulation based on sensory mismatch, VR research will benefit four-fold: (1) evaluating haptic immersion via ERPs does not require interrupting the user's immersive experience to ask questions. (2) The latter will further enable to conduct background evaluations of the user's sense of haptic immersion, enabling new paradigms for user studies in VR (using implicit measures). (3) ERPs are not subject to the same degree of introspection as the standard presence questionnaires. (4) This technique can be used as the building-block for VR applications that want to automatically adjust to the user's perception of conflicts, e.g., using our approach, an application could automatically adjust collision detection volumes based on the user's ERPs. 

%, (3) as companies start to offer VR headsets with embedded EEG-devices (such as LooxidVR), we believe this metric can be used to assess the level of immersion of a user in realtime, so that the VR application can adjust the haptic feedback automatically to best serve the user, without needing to stop and ask "calibration questions". 

\subsection{Limitations}
As with any system based on EEG, our approach has its inherent shortcomings: (1) ERP data is typically not taken per-trial but averaged over many trials and thus require high number of trial repetitions. In addition, (2) high-resolution EEG is still cumbersome to apply and requires time and expertise. However, researchers are working towards single-trial ERP analysis approaches ~\cite{blankertz_single-trial_2011}, and we do believe that new EEG systems will be directly embedded in future VR headsets allowing easy setup and recording of electrophysiological signals~\footnote{\label{VREEG}\url{http://looxidlabs.com/product/}, last accessed on 18/09/2018.} with new comfortable electrode types~\cite{nikulin_miniaturized_2010}, including dry electrodes~\cite{zander_evaluation_2017}. These EEG limitations put a cap on using our approach for quickly iterating on the design of a haptic VR scene. However, when designers want to develop and validate haptic immersion in VR scenarios without interrupting the user, our approach could, in the future offer, a potential replacement for questionnaires.